1
00:00:00,000 --> 00:00:03,009
想象一下哦，你的手机照片。

2
00:00:03,009 --> 00:00:06,019
嗯，瞬间变成梵骨或比卡。

3
00:00:06,019 --> 00:00:09,029
的风格，而且还是及时的对。

4
00:00:09,029 --> 00:00:12,039
啊，点几下就弄好了，这超库的。

5
00:00:12,039 --> 00:00:15,050
今天我们就要来深入探讨这背后的记。

6
00:00:15,050 --> 00:00:15,609
术。

7
00:00:15,609 --> 00:00:18,620
任意图像风格转换。

8
00:00:18,620 --> 00:00:21,629
看tensorflow是怎么办到的。嗯哼我们。

9
00:00:21,629 --> 00:00:24,640
手上这份资料就是tenorflow即使。

10
00:00:24,640 --> 00:00:27,649
任意图像风格转换202508。

11
00:00:27,649 --> 00:00:30,660
08点PDF对这份资料整。

12
00:00:30,660 --> 00:00:33,670
理的蛮清楚的，没错，所以今天的任务。

13
00:00:33,670 --> 00:00:36,679
就是要为你厘清一下。

14
00:00:36,679 --> 00:00:39,689
电脑他他到底怎么学会区分

15
00:00:39,689 --> 00:00:42,700
一张图的内容和风格。

16
00:00:42,700 --> 00:00:45,710
嗯，然后还要能做到又快又灵。

17
00:00:45,710 --> 00:00:46,399
如获。

18
00:00:46,399 --> 00:00:48,119
可以任意转换。

19
00:00:48,119 --> 00:00:51,130
最新的方法是怎么回事好，我们来。

20
00:00:51,130 --> 00:00:53,719
来好好梳理一下这个演进过程。

21
00:00:53,719 --> 00:00:56,729
呃，这个嘛可以从最早的开始说起。

22
00:00:56,729 --> 00:00:57,579
好啊。

23
00:00:57,579 --> 00:01:00,590
最早大概是2015年那个。

24
00:01:00,590 --> 00:01:03,600
他们的方法听说很厉害，但就是。

25
00:01:03,600 --> 00:01:03,979
是。

26
00:01:03,979 --> 00:01:06,989
呃，超级慢。对，没错，开创性。

27
00:01:06,989 --> 00:01:08,659
十足，但真的慢。

28
00:01:08,659 --> 00:01:11,670
一张图要算好几分钟，哎，哇，那也太。

29
00:01:11,670 --> 00:01:14,680
久了，他们是用预训练好的CNN。

30
00:01:14,680 --> 00:01:17,689
认为那个网络比较深层的地方，抓的是内容。

31
00:01:17,689 --> 00:01:20,700
就是物体的样子。嗯哼结构之类。

32
00:01:20,700 --> 00:01:23,709
对，然后浅层特征的那个统计下。

33
00:01:23,709 --> 00:01:24,450
相观性。

34
00:01:24,450 --> 00:01:27,459
他们用一个叫格拉姆矩阵的东西来。

35
00:01:27,459 --> 00:01:29,250
算代表风格。

36
00:01:29,250 --> 00:01:32,260
像是笔触啊、颜色啊这些哦。

37
00:01:32,260 --> 00:01:33,609
格拉姆举阵。

38
00:01:33,609 --> 00:01:36,180
听起来就蛮数学的，是有一点。

39
00:01:36,180 --> 00:01:37,870
但他最大的问题就是。

40
00:01:37,870 --> 00:01:40,879
每换一张内容图，或者想换个风。

41
00:01:40,879 --> 00:01:43,890
格就得重新跑一次那个很花时间的优。

42
00:01:43,890 --> 00:01:46,900
化计算每次都要重算，听起来很。

43
00:01:46,900 --> 00:01:49,359
不实用哎，对，这就是他的取舍。

44
00:01:49,359 --> 00:01:52,370
弹性是很高了，任何内容配任何风格。

45
00:01:52,370 --> 00:01:55,379
理论上都可以，但就是慢就是慢。

46
00:01:55,379 --> 00:01:58,390
在他直接去调输出图像的每个像素点。

47
00:01:58,590 --> 00:02:01,599
要让它同时向内容图的结构，又向。

48
00:02:01,599 --> 00:02:04,609
风格图的那个风格统计过程中那个。

49
00:02:04,609 --> 00:02:07,620
VGG网络是固定的，计算量非常大了。

50
00:02:07,620 --> 00:02:07,980
解。

51
00:02:07,980 --> 00:02:10,289
那后来大家一定想加速嘛。

52
00:02:10,289 --> 00:02:13,300
但听说嗯好像牺牲了。

53
00:02:13,300 --> 00:02:16,310
信没说，后来像johnson他们就提。

54
00:02:16,310 --> 00:02:19,319
出了那种快速的乾馈式的网络。乾。

55
00:02:19,319 --> 00:02:22,330
网路对，速度快到及时，可能几。

56
00:02:22,330 --> 00:02:25,340
毫秒就算完了。哇，那很快哎嗯。

57
00:02:25,340 --> 00:02:28,349
这代价就是每一个网路只能学会。

58
00:02:28,349 --> 00:02:30,069
一种特定的风格。

59
00:02:30,069 --> 00:02:31,750
啊。

60
00:02:31,759 --> 00:02:33,860
只能一种。对。

61
00:02:33,860 --> 00:02:36,870
你想用莫内的风格好训练一个。

62
00:02:36,870 --> 00:02:37,409
模型。

63
00:02:37,409 --> 00:02:40,419
想换成水墨风，那抱险要在另外。

64
00:02:40,419 --> 00:02:42,460
训练一个全新的模型。

65
00:02:42,460 --> 00:02:45,469
这样就失去了任意转换的意义了吗

66
00:02:45,469 --> 00:02:47,039
对不对就是说啊。

67
00:02:47,039 --> 00:02:50,050
所以当时最大的挑战，或者说大家最想。

68
00:02:50,050 --> 00:02:53,060
做的就是怎么结合两者的优点。

69
00:02:53,240 --> 00:02:56,250
又要像前馈网络那么快，又要向。

70
00:02:56,250 --> 00:02:59,259
原始方法那样能随心所欲换风格。

71
00:02:59,400 --> 00:03:02,409
这个听起来很难呢，关键在哪里啊

72
00:03:02,430 --> 00:03:05,439
关键就在于能不能设计一个网络。

73
00:03:05,439 --> 00:03:08,449
是可以在跑的时候才动态地把。

74
00:03:08,449 --> 00:03:11,460
风格资讯加进去，而不是一开始。

75
00:03:11,460 --> 00:03:14,219
就把风格写死在网络参数里面。

76
00:03:14,219 --> 00:03:17,229
动态注入。对，这就带我们到。

77
00:03:17,229 --> 00:03:19,080
真正的那个突破点了。

78
00:03:19,080 --> 00:03:22,090
这个突破是来自于对神经网络里面一个。

79
00:03:22,090 --> 00:03:25,099
叫硅一化成的东西有了新的理解。

80
00:03:25,099 --> 00:03:27,090
哦，归一化成。

81
00:03:27,090 --> 00:03:30,099
我知道好像有batch normalization。

82
00:03:30,099 --> 00:03:33,110
哎，还有一个叫实力归一化instance.

83
00:03:33,110 --> 00:03:35,189
ization简称IN。

84
00:03:35,240 --> 00:03:38,250
后来研秀发现这个IN啊，他跟。

85
00:03:38,250 --> 00:03:41,259
不像风格的关系好像很大哎。

86
00:03:41,259 --> 00:03:44,270
instance normalization跟风格有关这怎么。

87
00:03:44,270 --> 00:03:44,909
说。

88
00:03:44,909 --> 00:03:46,810
这就催生了A的IN。

89
00:03:46,810 --> 00:03:49,819
也就是自适应实力归一化的核心想法。

90
00:03:49,819 --> 00:03:50,349
吧。

91
00:03:50,349 --> 00:03:51,409
大家发现。

92
00:03:51,409 --> 00:03:54,419
IN再把每个样本的特征图做标准。

93
00:03:54,419 --> 00:03:57,430
话用他自己的均值和标准差。

94
00:03:57,430 --> 00:04:00,439
嗯哼的时候好像哎不知不觉就。

95
00:04:00,439 --> 00:04:03,449
把风格资讯给抹掉了，把风格抹掉了。

96
00:04:03,449 --> 00:04:06,460
对，因为风格常常就体现在那些。

97
00:04:06,460 --> 00:04:07,719
统计特性上。

98
00:04:07,719 --> 00:04:08,300
那。

99
00:04:08,300 --> 00:04:11,310
反过来想好了，如果IN会抹除。

100
00:04:11,310 --> 00:04:14,319
风格。那我是不是可以反过来强行。

101
00:04:14,319 --> 00:04:17,329
请把内容特征的均值和标准差换。

102
00:04:17,329 --> 00:04:20,339
成目标风格图像算出来的均子和标准。

103
00:04:20,339 --> 00:04:23,350
哦，用风格图的统计。

104
00:04:23,350 --> 00:04:26,360
数据去取代内容图的。没错。

105
00:04:26,360 --> 00:04:29,370
这样是不是就能把新的风格赋予给内容特。

106
00:04:29,370 --> 00:04:31,449
这想法很妙，哎。

107
00:04:31,449 --> 00:04:34,459
所以A大N实际上是怎么操作的

108
00:04:34,459 --> 00:04:35,660
操作其实很直接。

109
00:04:35,660 --> 00:04:38,670
他先把内容图的特征图透过IN。

110
00:04:38,670 --> 00:04:41,329
洗掉他自己的风格统计数据。

111
00:04:41,329 --> 00:04:44,339
也就是用他自己的均值和标准差把它标准化。

112
00:04:44,339 --> 00:04:47,350
嗯哼变成一个比较干净的内容特征。

113
00:04:47,350 --> 00:04:50,360
对，然后再用风格图像算出来的那。

114
00:04:50,360 --> 00:04:52,629
这个均值和标准差。

115
00:04:52,629 --> 00:04:55,639
对这个标准化后的内容特征。

116
00:04:55,639 --> 00:04:57,060
我一个缩放很平移。

117
00:04:57,060 --> 00:05:00,069
嗯，所以数学上就是简单说就是。

118
00:05:00,069 --> 00:05:01,189
A代IN。

119
00:05:01,189 --> 00:05:03,240
内容特征、风格特征。

120
00:05:03,240 --> 00:05:06,250
等于风格标准差标准化。

121
00:05:06,250 --> 00:05:09,259
后的内容特征plus风格均值。

122
00:05:09,389 --> 00:05:10,449
了解。

123
00:05:10,449 --> 00:05:13,459
最重要的一点是A单安这一层本。

124
00:05:13,459 --> 00:05:16,470
神他没有需要学习的参数风格的。

125
00:05:16,470 --> 00:05:19,480
那个均值标准差是从风格图。

126
00:05:19,480 --> 00:05:22,490
及时算出来的哇，这真的是一个观念。

127
00:05:22,490 --> 00:05:23,930
上的大跃进哎。

128
00:05:23,930 --> 00:05:26,939
等于是把风格这么抽象的东西。

129
00:05:26,939 --> 00:05:29,949
简化成可以及时抽换的统计。

130
00:05:29,949 --> 00:05:32,959
签名也就是均值跟标准差可以。

131
00:05:32,959 --> 00:05:35,970
这么理解，难怪速度可以比那个轻天。

132
00:05:35,970 --> 00:05:38,980
复杂的格拉姆矩阵快这么多。正是如。

133
00:05:38,980 --> 00:05:41,990
止有了A单一个很典型的。

134
00:05:41,990 --> 00:05:43,360
架构就出现了。

135
00:05:43,360 --> 00:05:45,220
像编码器。

136
00:05:45,300 --> 00:05:48,310
AWIN解码器编码器。

137
00:05:48,310 --> 00:05:50,769
AEN解码器。对。

138
00:05:50,769 --> 00:05:53,779
编码器先把内容图压缩，提取。

139
00:05:53,779 --> 00:05:55,060
与结构特征。

140
00:05:55,060 --> 00:05:58,069
中间的A单IN层负责混合。

141
00:05:58,069 --> 00:06:01,079
和这个内容结构，还有目标风格的同。

142
00:06:01,079 --> 00:06:04,089
计数据最后再通过一个训练。

143
00:06:04,089 --> 00:06:05,209
变好的解码器。

144
00:06:05,209 --> 00:06:08,220
把这个混合后的特征重建回。

145
00:06:08,220 --> 00:06:10,579
最终的风格化图像嗯哼。

146
00:06:10,680 --> 00:06:13,689
这个架构听起来很合理。那像天。

147
00:06:13,689 --> 00:06:16,699
h上面，酷宫美娟塔团队提供的那个。

148
00:06:16,699 --> 00:06:19,709
个模型呢资料里提到它是用双网。

149
00:06:19,709 --> 00:06:21,920
路架构，这又是为什么

150
00:06:22,329 --> 00:06:24,569
那个模型稍微有点不一样。

151
00:06:24,639 --> 00:06:27,649
他有一个专门的风格预测网路。

152
00:06:27,649 --> 00:06:30,660
先把风格图像压缩成一个比较精简。

153
00:06:30,660 --> 00:06:33,670
的风格向量可能就是一串数字。

154
00:06:33,670 --> 00:06:36,680
比如说10百维哦，先把风格变成一个向量。

155
00:06:36,680 --> 00:06:37,220
对。

156
00:06:37,220 --> 00:06:40,230
然后再把这个风格向量跟内容图像。

157
00:06:40,230 --> 00:06:43,240
一起为给另一个风格转换网络去产生。

158
00:06:43,240 --> 00:06:45,910
最后的结果这样设计有什么好处吗

159
00:06:45,910 --> 00:06:48,920
这样设计可能效率更高，或者能更好。

160
00:06:48,920 --> 00:06:51,930
好的去表示和融合不同的风格。

161
00:06:51,930 --> 00:06:54,939
比如说你甚至可以把不同风格算出来的向量。

162
00:06:54,939 --> 00:06:57,949
加权平均就能做出混合风格的效果。

163
00:06:57,949 --> 00:07:00,959
换歌风格，听下tensorflow。

164
00:07:00,959 --> 00:07:03,970
让一般人就算不是专家，也能很轻松的玩。

165
00:07:03,970 --> 00:07:06,980
这个技术了非常方便，基本上你就是。

166
00:07:06,980 --> 00:07:09,990
用hub load这个指令去载如。

167
00:07:09,990 --> 00:07:13,000
像magen他们提供的那个预训练模型。

168
00:07:13,000 --> 00:07:16,009
Arbitrary image stylization.

169
00:07:16,009 --> 00:07:19,019
one two five six,这个要把你的内容图。

170
00:07:19,019 --> 00:07:22,029
5、风格图准备好，可能要做点预处理。

171
00:07:22,029 --> 00:07:24,220
像是载入缩放大小。

172
00:07:24,220 --> 00:07:26,420
数值弄到0到1之间。

173
00:07:26,420 --> 00:07:28,860
标准的图像处理步骤。对。

174
00:07:28,860 --> 00:07:31,870
然后就一行城市嘛，oppos等于。

175
00:07:31,870 --> 00:07:34,879
9、内容图张量、风格图张量。

176
00:07:34,879 --> 00:07:37,889
结果就出来了，及时的艺术创作。

177
00:07:37,889 --> 00:07:40,899
真的可以说是非常容易上手。听起来真的。

178
00:07:40,899 --> 00:07:43,910
很美好又快又灵活。不过。

179
00:07:43,910 --> 00:07:46,920
他完美吗我记得资料里面好像。

180
00:07:46,920 --> 00:07:49,930
像也提到一些视觉上的问题，artacts。

181
00:07:49,930 --> 00:07:52,939
之类的没错没错，这种简化把。

182
00:07:52,939 --> 00:07:55,949
风格简化成均值和标准差是。

183
00:07:55,949 --> 00:07:58,959
有代价的代价是什么有时候他可能。

184
00:07:58,959 --> 00:08:01,970
会丢失一些比较细腻的风格资讯。

185
00:08:01,970 --> 00:08:04,980
比如说一些特殊的纹理呀或者空间上。

186
00:08:04,980 --> 00:08:07,990
的结构嗯，结构可能就是。

187
00:08:07,990 --> 00:08:10,250
输出的图像内容有点模糊。

188
00:08:10,250 --> 00:08:13,259
或者风格贴的不太自然，感觉像是。

189
00:08:13,259 --> 00:08:14,540
并加上去的。

190
00:08:14,540 --> 00:08:17,550
有时候物体的边缘甚至会变形哦，会有。

191
00:08:17,550 --> 00:08:20,560
这种状况。对，尤其当内容和风格。

192
00:08:20,560 --> 00:08:23,569
在原始图像中纠缠的比较紧密的时候。

193
00:08:23,569 --> 00:08:26,579
你硬是把统计量换掉，有时候会。

194
00:08:26,579 --> 00:08:29,589
把重建内容需要的一些关键资讯也。

195
00:08:29,589 --> 00:08:32,600
一起破坏掉了。了解，那未来呢。

196
00:08:32,600 --> 00:08:35,610
大家还在研究哪些改进的方向研究到。

197
00:08:35,610 --> 00:08:38,620
当然没有停下来，比如说有人尝试饮。

198
00:08:38,620 --> 00:08:39,980
有注意力机制。

199
00:08:39,980 --> 00:08:42,990
让模型更知道要关注内容图像的哪。

200
00:08:42,990 --> 00:08:46,000
哪些重要区域让风格转换更聪。

201
00:08:46,000 --> 00:08:47,090
明一点。对。

202
00:08:47,090 --> 00:08:50,100
还有用更复杂的数学变换，像是。

203
00:08:50,100 --> 00:08:53,110
WCT中文叫白话与折色。

204
00:08:53,110 --> 00:08:53,700
变换。

205
00:08:53,700 --> 00:08:56,710
他试图去匹配比特征均值标准。

206
00:08:56,710 --> 00:08:58,889
检查更高阶的一些统计特性。

207
00:08:58,889 --> 00:09:01,899
希望能捕捉到更丰富的风格细节。

208
00:09:01,899 --> 00:09:04,909
提高保证度，听起来更复杂了。还有啊。

209
00:09:04,909 --> 00:09:07,919
现在很红的那个扩散模型diffusion models。

210
00:09:07,940 --> 00:09:10,950
也有人开始用他们来做风格转换，效果可能更。

211
00:09:10,950 --> 00:09:13,960
好哦，连diiffusion都用上了。是啊。

212
00:09:13,960 --> 00:09:16,970
另外一个大挑战是在影片这种应用上。

213
00:09:16,970 --> 00:09:19,980
影片对你要怎么维持风格在连续。

214
00:09:19,980 --> 00:09:22,990
的画面里面是稳定的，不会闪来闪去。

215
00:09:23,190 --> 00:09:26,200
这个时间一致性是个大问题嗯。

216
00:09:26,200 --> 00:09:27,730
这确实很重要。

217
00:09:27,730 --> 00:09:30,740
好了，我们今天这样梳理下来这。

218
00:09:30,740 --> 00:09:33,750
对你来说到底意味着什么呢嗯。

219
00:09:34,340 --> 00:09:37,350
一步步演变成现在这种。

220
00:09:37,350 --> 00:09:40,360
时又可以任意换风格的技术。没错。

221
00:09:40,360 --> 00:09:41,389
而且。

222
00:09:41,389 --> 00:09:44,399
tenorflow hub让这个很强大的工具。

223
00:09:44,399 --> 00:09:47,409
离你其实非常近，可能就几行。

224
00:09:47,409 --> 00:09:50,419
城市嘛而已。对，所以不管你是想快速。

225
00:09:50,419 --> 00:09:53,429
就帮自己的诈骗换个酷炫的艺术风格。

226
00:09:53,429 --> 00:09:56,440
还是你对AI生成艺术背后的原理感到好。

227
00:09:56,440 --> 00:09:59,450
好奇，希望我们这一次的讨论对你有点。

228
00:09:59,450 --> 00:10:00,879
启发嗯哼。

229
00:10:00,879 --> 00:10:03,889
最后啊我想留一个有趣的问题给大家。

230
00:10:03,889 --> 00:10:06,899
思考一下，我们看到在这个技术。

231
00:10:06,899 --> 00:10:09,909
风格被定义成了特征的统。

232
00:10:09,909 --> 00:10:10,899
技术去。

233
00:10:10,899 --> 00:10:13,909
像是菌子含变异术。对一个。

234
00:10:13,909 --> 00:10:15,190
很数学的定义。

235
00:10:15,190 --> 00:10:18,200
但艺术风格的本质真的就只是。

236
00:10:18,200 --> 00:10:19,379
这样吗

237
00:10:19,379 --> 00:10:22,389
随着AI模型越来越厉害，越来越强。

238
00:10:22,389 --> 00:10:25,399
恒大他们有没有可能不只是模仿我们。

239
00:10:25,399 --> 00:10:28,409
已有的风格嗯，而是开始创造出。

240
00:10:28,409 --> 00:10:31,419
我们从来没见过，甚至无法想象的。

241
00:10:31,419 --> 00:10:34,429
那种真正原创的全新的。

242
00:10:34,429 --> 00:10:37,129
AI艺术风格呢这个问题很有意思。

243
00:10:37,129 --> 00:10:40,139
这点或许值得我们好好期待，也好好。

244
00:10:40,139 --> 00:10:41,110
思考一下。
